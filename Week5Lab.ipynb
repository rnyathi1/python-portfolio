{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2a4052-25a0-4482-9565-e046920fcaeb",
   "metadata": {},
   "source": [
    "# Practical Business Analytics Week 5 Lab - Time Series\n",
    "\n",
    "The lab from this week looks at processing time series data and applying neural networks to sequential data.\n",
    "\n",
    "Work through the cells in this Jupyter Notebook, following the instructions in the text boxes to load and analyse the data.\n",
    "\n",
    "Run the cells below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94099c5d-e99b-47b0-8de3-d2dd4690ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e446c64-67db-4e40-839a-90baf3a9608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import yfinance as yahooFinance\n",
    "from statsmodels.tsa import seasonal\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc00c8-be3d-4624-8c50-ade5455dbdb1",
   "metadata": {},
   "source": [
    "## Encoding time values\n",
    "\n",
    "First we will look at how we can write functions to encode a time in a 24 hour clock format \"HH\\:MM\\:SS\" (for example \"15\\:15\\:00\" for 3.15pm) into a pair of numeric features.\n",
    "\n",
    "We will start by using the Python *datetime* library to generate Python objects corresponding to a particular time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb348e72-b32d-4a9f-8f46-109770d103e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "midday = datetime.time.fromisoformat(\"12:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51adc96e-6bd3-4eb7-a725-dea4382dc325",
   "metadata": {},
   "source": [
    "From this Python object we can access the hour, minutes and seconds of the time using the *hour*, *minute* and *second* attributes of the *midday* object.\n",
    "\n",
    "```python\n",
    "print(midday.hour) # 12\n",
    "```\n",
    "\n",
    "Try extracting the minute below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c431c-303d-48e0-9c6a-2b0d65206348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c154d2-076c-40d2-8009-70f63d54fe66",
   "metadata": {},
   "source": [
    "We are going to construct a function than takes the number of seconds from midnight and converts this into two features. The first step towards doing this is to calculate the number of seconds from midnight from a Python *time* object.\n",
    "\n",
    "Given that there are 60 seconds in a minute and 60 minutes in an hour, write a Python function that takes a *time* object and returns the number of second from midnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed60f84-48ca-4410-815e-fb2058825b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "511a8bed-21f8-41cc-9d7a-2d90e689f1ed",
   "metadata": {},
   "source": [
    "Test the function using the time object below. You should get a result of $70650$ seconds\n",
    "\n",
    "```python\n",
    "test_time = datetime.time.fromisoformat(\"19:37:30\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81791e3d-1179-4bec-81f9-93ad7d9a8942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f308e4f2-eb44-4fb7-85a1-648a3b0fe189",
   "metadata": {},
   "source": [
    "Now we will construct two features from the time in seconds. To do this we will use the following two formulae:\n",
    "\n",
    "$$\\textrm{Feature}_1 = \\cos{\\frac{2\\pi s}{S}}$$\n",
    "\n",
    "$$\\textrm{Feature}_1 = \\sin{\\frac{2\\pi s}{S}}$$\n",
    "\n",
    "where $s$ is the time in seconds from midnight, and $S$ is the total number of seconds in a day.\n",
    "\n",
    "Write a Python function to calculate these two features from the time in seconds from midnight.\n",
    "\n",
    "You can use the *math.sin()* and *math.cos()* functions to calculate sine and cosine, and *math.pi* for the value of pi. To return two values from a Python function, create a pair to return:\n",
    "\n",
    "```python\n",
    "return (a,b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e8732-40e0-44e4-aad7-e9eae355bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf17239f-24c1-4efb-92a7-94fe3ade2d5c",
   "metadata": {},
   "source": [
    "We can combine these functions to build a function that takes a string as input and returns the two features as output.\n",
    "\n",
    "It will look something like:\n",
    "\n",
    "```python\n",
    "def timeToFeatures(ts):\n",
    "    time = datetime.time.fromisoformat(ts)\n",
    "    seconds = ...\n",
    "    x,y = ...\n",
    "    return (x,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9f43f-6b94-4371-8667-aa2b8d8f6a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a6b71dc-be32-4157-8e38-fcdcf93b3305",
   "metadata": {},
   "source": [
    "Test your function using:\n",
    "\n",
    "```python\n",
    "timeToFeatures(\"23:59:00\")\n",
    "```\n",
    "\n",
    "The output should look like\n",
    "\n",
    "```python\n",
    "(0.9999904807207345, -0.004363309284747432)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe530699-d66a-45b0-9089-55be19416f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea66459-36f8-4330-a1e2-92a7ef4aa748",
   "metadata": {},
   "source": [
    "It would be interesting to visualise these two features over a 24 hour period. We can generate a list of input time strings using:\n",
    "\n",
    "```python\n",
    "times = [\"{:02d}\".format(h)+\":00:00\" for h in range(24)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a5974-8058-4850-a249-d1afcbbfb121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4d0ed8-0641-48b5-94f1-87253dc8231c",
   "metadata": {},
   "source": [
    "We can create a pandas DataFrame with a column for the time using:\n",
    "\n",
    "```python\n",
    "d = pd.DataFrame({\"Time\":times})\n",
    "```\n",
    "\n",
    "Do this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c36635-3725-4b34-bc7d-c4b431ba7392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb89d84-ebcc-485c-b9e0-edab66879d9e",
   "metadata": {},
   "source": [
    "To generate the features, we can use the pandas *map* method to apply our function to each value in the Time column. Then we can plot the resulting features. The python code below applies the timeToFeatures function to each time and stores the values of the two features in the *x* and *y* columns.\n",
    "\n",
    "```python\n",
    "d[\"x\"]=d[\"Time\"].map(lambda t: timeToFeatures(t)[0])\n",
    "d[\"y\"]=d[\"Time\"].map(lambda t: timeToFeatures(t)[1])\n",
    "d.plot()\n",
    "```\n",
    "\n",
    "Run this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52993f60-2df1-4afa-8351-0726e359db87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2cfdddf-d5ec-44d6-8d19-2e535b4444cf",
   "metadata": {},
   "source": [
    "## Predicting stock values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ad602ad-59bb-465d-8529-5599d9ba02c4",
   "metadata": {},
   "source": [
    "Stock prices are a typical example of a classical time series.\n",
    "We can get historic daily stock prices (so each price is from a fixed time of day) from the web up to yesterday and then build our neural models to predict possible future values.\n",
    "\n",
    "For this experiment, I have used:\n",
    " - The first 70% of the stock prices, in date order, to TRAIN the neural network\n",
    " - The remaining 30% of the stock prices, so the newest dates, to TEST the neural network\n",
    "\n",
    "As we discussed in the lecture, you would no doubt implement a robust time series cross validation evaluation approach (sliding window or forward chaining).\n",
    "\n",
    "First we will download and plot the Google stock data.\n",
    "\n",
    "```python\n",
    "stock = yahooFinance.Ticker(\"GOOG\")\n",
    "stock_data = stock.history(period=\"max\")\n",
    "stock_data['Open'].plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19912b6-66d7-4abd-bc2f-34b72a1c8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "319b3848-4a1d-4b24-afc5-133b235e361c",
   "metadata": {},
   "source": [
    "We can break down the timeseries into the overall trend, seasonal changes, and residuals, using the decompose function in *statsmodels*.\n",
    "\n",
    "Notice that as well as the overall trend, there are also seasonal changes detected.\n",
    "\n",
    "```python\n",
    "dec=seasonal.seasonal_decompose(stock_data[\"Open\"],period=365)\n",
    "dec.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be39a19-f9c1-44c3-be46-19e3f7636bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b28585b5-ccbb-4961-9689-07b36f80fbb1",
   "metadata": {},
   "source": [
    "### Deep neural network prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c20557-2f6d-437a-8827-32c0f4a376df",
   "metadata": {},
   "source": [
    "In this experiment, we are going to use a fixed number of previous days stock prices to predict the next day price using a deep neural network. We will use the previous $n$ time steps at $t-1,t-2,\\ldots,t-n$, to predict the next time step $t$.\n",
    "\n",
    "We will be using the **Keras** library to build and train our neural network models. You can read about **Keras** on the website: https://keras.io/\n",
    "\n",
    "Keras is a neural network library that can work on top of popular frameworks like Tensorflow, JAX, and Torch, and provides implementations of many common neural network architectures.\n",
    "\n",
    "The first thing we need to do is detrend the data, which we can do by calculating the mean with a *rolling window*. Fortunately pandas has built in functions that can do this for us.\n",
    "\n",
    "We will calculate the means using\n",
    "\n",
    "```python\n",
    "stock_means = stock_data[\"Open\"].rolling(10,min_periods=1).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fbf4d-3d31-4139-9855-ea77a02787d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5630e7d4-f12c-4d18-8cc6-ef60196dfd76",
   "metadata": {},
   "source": [
    "We will now process the stock data by scaling it by the mean, and then adjusting so it is between $0$ and $1$. To do this we will first divide the stock data by the means we calculated above, and store this in a new DataFrame:\n",
    "\n",
    "```python\n",
    "stock_scaled = stock_data[\"Open\"]/stock_means\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc3249-2e57-4661-a3ed-a17a0d5e2348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd2e571-d947-4a3a-8294-2261af02744f",
   "metadata": {},
   "source": [
    "Then we can use the minimum and maximum values to transform to be between $0$ and $1$. If the minimum is *stock_min* and maximum is *stock_max* we can use:\n",
    "\n",
    "$$\\textrm{stock\\_norm} = \\frac{\\textrm{stock\\_scaled}-\\textrm{stock\\_min}}{\\textrm{stock\\_max}-\\textrm{stock\\_min}}$$\n",
    "\n",
    "To find the minimum of a dataframe *d*, you can use the method *d.min()*, and for the maximum, *d.max()*. Write Python code to create a normalised stock timeseries, *stock_norm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c55df-11bc-463a-b0cf-8bdeacd18fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bebd587-bc8a-435b-b0f9-2e241e1d5f53",
   "metadata": {},
   "source": [
    "Now plot the normalised and detrended data using the *stock_norm.plot()* method of your normalised stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b6675-4e05-42cb-b648-7cc442f000e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bb3dc6-8b90-48cd-9d0d-0d220bc4643b",
   "metadata": {},
   "source": [
    "#### Rolling windows\n",
    "\n",
    "To generate a dataset for training, we can use a builtin function of the keras library to generate a dataset object that returns data points at $t-1,t-2,\\ldots,t-n$ as the features (X), and the data point at $t$ as the target (y).\n",
    "\n",
    "To see this in an example, we will create an array of values from 1 to 100, and take consecutive data points from it, with $n=10$.\n",
    "\n",
    "```python\n",
    "data = np.arange(1,101) # Generate a range from 1 to 100\n",
    "input_data = data[:-10] # Leave off the last 10 values\n",
    "targets = data[10:] # The targets start at the value at index 10\n",
    "dataset = timeseries_dataset_from_array(input_data,targets,sequence_length=10,batch_size=1).as_numpy_iterator()\n",
    "for i in range(1,6):\n",
    "  print(\"Step\",i)\n",
    "  inputs, targets = next(dataset) # fetch the next X and y values\n",
    "  print(\"X:\",inputs[0]) \n",
    "  print(\"y:\",targets[0])\n",
    "```\n",
    "\n",
    "Try this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c200392-3c0f-4084-9c6c-e35bed079354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f64c63-c620-4ec0-92e0-3af5bf27aa46",
   "metadata": {},
   "source": [
    "For a time series we cannot randomly select data for a train and test split, so instead we will take the first $70/%$ of the data as training and the remaining $30\\%$ as test. Then we will create timeseries datasets from these using Keras.\n",
    "\n",
    "```python\n",
    "rows = stock_norm.shape[0]\n",
    "stock_train = stock_norm.iloc[0:int(0.7*rows)]\n",
    "stock_test = stock_norm.iloc[(int(0.7*rows)+1):rows]\n",
    "n = 10 # Set n=10 to start with\n",
    "rolling_stock_train = timeseries_dataset_from_array(stock_train[:-n], stock_train[n:], sequence_length=n,batch_size=128)\n",
    "rolling_stock_test = timeseries_dataset_from_array(stock_test[:-n], stock_test[n:], sequence_length=n,batch_size=128)\n",
    "```\n",
    "\n",
    "Run this code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfb283-0997-494f-89a2-7c5b86549942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4601b88f-7bee-4f39-aca8-7ff5ce2da286",
   "metadata": {},
   "source": [
    "Now we will create and train a dense neural network model using Keras. Dense neural networks are composed of fully connected layers, where every neuron in a layer is connected to every neuron in the previous layer. We will use the Keras API to generate a dense network with three layers, and a \"relu\" activation function.\n",
    "\n",
    "The final layer is the output, and has a linear activation as we are predicting a continuous value.\n",
    "\n",
    "The model is then compiled and trained on our training data.\n",
    "\n",
    "```python\n",
    "dense_model = keras.Sequential()\n",
    "dense_model.add(layers.Input((n,)))\n",
    "dense_model.add(layers.Dense(50,activation='relu'))\n",
    "dense_model.add(layers.Dense(20,activation='relu'))\n",
    "dense_model.add(layers.Dense(1,activation='linear'))\n",
    "\n",
    "dense_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss='mean_squared_error')\n",
    "dense_model.fit(rolling_stock_train,epochs=20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a345a9-83fe-4b36-b815-054cdd7aaf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59b780c-5111-408a-ad72-d47c993c66d9",
   "metadata": {},
   "source": [
    "Now we can plot the predictions made by the model, offsetting the test data to take into account that our first prediction is at index $n+1$.\n",
    "\n",
    "```python\n",
    "pred = dense_model.predict(rolling_stock_test)\n",
    "l = pred.shape[0]\n",
    "output = pd.DataFrame(stock_test.iloc[n:(n+l)])\n",
    "output[\"Prediction\"] = pred\n",
    "output.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc94c3-ba5a-4054-9988-c56f7a2b6db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaf6b500-e924-4280-b713-559355481b6f",
   "metadata": {},
   "source": [
    "We can also construct a **reccurent** neural network in Keras, using the LSTM layer. LSTM stands for Long Short-Term Memory and is used to work with sequential data. We will create and fit a model using the Keras builtin LSTM layers.\n",
    "\n",
    "```python\n",
    "rnn_model = keras.Sequential()\n",
    "rnn_model.add(layers.Input((n,1)))\n",
    "rnn_model.add(layers.LSTM(50,return_sequences=True))\n",
    "rnn_model.add(layers.LSTM(30,return_sequences=False))\n",
    "rnn_model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "rnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss='mean_squared_error')\n",
    "rnn_model.fit(rolling_stock_train,epochs=20)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b01d25-73fc-479b-85ca-5ec94dad1e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01feead-e0e6-4919-a921-a8a83a0af6e1",
   "metadata": {},
   "source": [
    "Again we can plot the predictions compared to the true values:\n",
    "\n",
    "```python\n",
    "pred = rnn_model.predict(rolling_stock_test)\n",
    "l = pred.shape[0]\n",
    "output = pd.DataFrame(stock_test.iloc[n:(n+l)])\n",
    "output[\"Prediction\"] = pred\n",
    "output.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54be3d-44d9-44fc-9ef4-5efcb1914b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f717aef-ecf1-411c-a67b-1e136bcb8320",
   "metadata": {},
   "source": [
    "### Plotting on the original scale\n",
    "\n",
    "We might want to plot our predictions for the test data on the original scale with the data before it was detrended. To do this, we need the mean values used to detrend the test data, and the original opening prices. We can find this data using:\n",
    "\n",
    "```python\n",
    "stock_data_test=stock_data[\"Open\"].iloc[(int(0.7*rows)+1):rows].iloc[n:(n+l)] # Original un-normalised stock data\n",
    "stock_means_test=stock_means.iloc[(int(0.7*rows)+1):rows].iloc[n:(n+l)] # Means used for detrending the test data\n",
    "```\n",
    "\n",
    "Using these see if you can generate a dataframe with the original stock data and un-normalised predictions. To do this you will need to first undo the normalisation, and then multiply by the means. Remember the data were normalised using:\n",
    "\n",
    "$$\\textrm{stock\\_norm} = \\frac{\\textrm{stock\\_scaled}-\\textrm{stock\\_min}}{\\textrm{stock\\_max}-\\textrm{stock\\_min}}$$\n",
    "\n",
    "To undo this you will first need to multiply by $\\textrm{stock\\_max}-\\textrm{stock\\_min}$, before adding $\\textrm{stock\\_min}$. Finally you will need to multiply these values by the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b594e8-98ff-44cc-a418-d0b35b0b9a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c655a1-473f-4565-a378-b96b3d8261dd",
   "metadata": {},
   "source": [
    "## Optional extras\n",
    "\n",
    "Try experimenting with different numbers of layers and neurons in the neural networks used above. For example to create a dense layer with 100 neurons as part of your model you would use:\n",
    "\n",
    "```python\n",
    "dense_model.add(layers.Dense(100,activation='relu'))\n",
    "```\n",
    "\n",
    "You can add this to the existing model definition between the input and final layer.\n",
    "\n",
    "Experiment with both the dense and LSTM networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be958b1c-f4c5-45d7-ac67-c4d14c1bed91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
